{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Predictive Maintenance"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Workspace"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    credential = InteractiveBrowserCredential()\n",
        "\n",
        "ml_client = MLClient.from_config(credential=credential)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1748368695635
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Setup"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create environment directory."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dependencies_folder = 'env'\n",
        "os.makedirs(dependencies_folder, exist_ok=True)\n",
        "print(dependencies_folder, 'folder created')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "env folder created\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1748372676389
        },
        "jupyter": {
          "source_hidden": true
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {dependencies_folder}/conda.yaml\n",
        "name: sklearn-env\n",
        "channels:\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.8\n",
        "  - pip\n",
        "  - scikit-learn=1.3.2\n",
        "  - scipy\n",
        "  - imbalanced-learn\n",
        "  - numpy=1.24.3\n",
        "  - xgboost\n",
        "  - pandas\n",
        "  - seaborn\n",
        "  - matplotlib\n",
        "  - pip:  \n",
        "    - azureml-mlflow\n",
        "    - mlflow==2.17.2\n",
        "    - azure-ai-ml\n",
        "    - azureml-inference-server-http"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting env/conda.yaml\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register environment in workspace."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "custom_env_name = \"sklearn-env\"\n",
        "\n",
        "pdm_env = Environment(\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n",
        "    conda_file=os.path.join(dependencies_folder, \"conda.yaml\"),\n",
        "    name=custom_env_name,\n",
        "    description=\"Environment for Predictive Maintenance with Ensemble Stacking\",\n",
        ")\n",
        "job_env = ml_client.environments.create_or_update(pdm_env)\n",
        "\n",
        "print(\n",
        "    f\"Environment with name {job_env.name} is registered to workspace, the environment version is {job_env.version}\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Environment with name sklearn-env is registered to workspace, the environment version is 4\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1748372702685
        },
        "jupyter": {
          "source_hidden": true
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register raw data in workspace."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "my_data = Data(\n",
        "    path=\"./data/ai4i2020-predictive-maintenance.csv\",\n",
        "    type=AssetTypes.URI_FILE,\n",
        "    name=\"predictive_maintenance_raw_data\",\n",
        "    description=\"AI4I 2020 Predictive maintenance dataset\"\n",
        ")\n",
        "ml_client.data.create_or_update(my_data)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\r\u001b[32mUploading ai4i2020-predictive-maintenance.csv\u001b[32m (< 1 MB): 0.00B [00:00, ?B/s]\r\u001b[32mUploading ai4i2020-predictive-maintenance.csv\u001b[32m (< 1 MB): 100%|██████████| 522k/522k [00:00<00:00, 12.6MB/s]\n\u001b[39m\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "Data({'path': 'azureml://subscriptions/55fc198d-597c-451e-9372-e172883e1ef0/resourcegroups/case-study-rg/workspaces/ml-intern-ws/datastores/workspaceblobstore/paths/LocalUpload/ced9beaca6dde675927114399c8cc851/ai4i2020-predictive-maintenance.csv', 'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': None, 'type': 'uri_file', 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'predictive_maintenance_raw_data', 'description': 'AI4I 2020 Predictive maintenance dataset', 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/55fc198d-597c-451e-9372-e172883e1ef0/resourceGroups/case-study-rg/providers/Microsoft.MachineLearningServices/workspaces/ml-intern-ws/data/predictive_maintenance_raw_data/versions/1', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/jmanuel/code/Users/jemima.simone.manuel/predictive-maintenance', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7605640c0c40>, 'serialize': <msrest.serialization.Serializer object at 0x7605640cf4c0>, 'version': '1', 'latest_version': None, 'datastore': None})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1747192577049
        },
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": true
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating script directory."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "script_folder = 'src'\n",
        "os.makedirs(script_folder, exist_ok=True)\n",
        "print(script_folder, 'folder created')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "src folder created\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1748368695845
        },
        "jupyter": {
          "source_hidden": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create script for preparing data."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {script_folder}/prep-data.py\n",
        "\n",
        "import argparse\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "from azure.identity import DefaultAzureCredential\n",
        "import os\n",
        "import joblib\n",
        "\n",
        "def main(args):\n",
        "    input_path = args.input_data\n",
        "    output_dir = args.output_data\n",
        "    scaler_full_output_path = args.scaler_output_data\n",
        "    num_cols = ['Rotational speed', 'Tool wear']\n",
        "    float_cols = ['Air temperature', 'Process temperature', 'Rotational speed', 'Torque', 'Tool wear']\n",
        "    threshold_unique = 90\n",
        "    infrequent_threshold = 0.05\n",
        "\n",
        "    print(f\"Reading data from: {input_path}\")\n",
        "    df = read_data(input_path)\n",
        "    print(f\"Initial data shape: {df.shape}\")\n",
        "\n",
        "    print(\"Cleaning data...\")\n",
        "    cleaned_df = clean_data(df)\n",
        "    print(f\"Cleaned data shape: {cleaned_df.shape}\")\n",
        "\n",
        "    print(\"Renaming features...\")\n",
        "    renamed_df = rename_features(cleaned_df)\n",
        "    print(f\"Shape after renaming: {renamed_df.shape}\")\n",
        "\n",
        "    print(\"Converting numerical columns to float...\")\n",
        "    normalized_df = num_to_float(renamed_df, num_cols)\n",
        "    print(f\"Shape after float conversion: {normalized_df.shape}\")\n",
        "\n",
        "    print(f\"Dropping columns with more than {threshold_unique}% unique values...\")\n",
        "    dropped_df = drop_high_unique_cols(normalized_df, threshold=threshold_unique)\n",
        "    print(f\"Shape after dropping high unique columns: {dropped_df.shape}\")\n",
        "\n",
        "    print(\"Creating 'Failure type' column...\")\n",
        "    add_col_df = create_failure_type(dropped_df)\n",
        "    print(f\"Shape after creating 'Failure type': {add_col_df.shape}\")\n",
        "\n",
        "    print(\"Encoding categorical features...\")\n",
        "    encoded_df = label_enc(add_col_df)\n",
        "    print(f\"Shape after encoding: {encoded_df.shape}\")\n",
        "\n",
        "    print(\"Scaling numerical features...\")\n",
        "    scaled_df, scaler = scaling_data(encoded_df, float_cols)\n",
        "    print(f\"Shape after scaling: {scaled_df.shape}\")\n",
        "\n",
        "    print(\"Removing target anomalies...\")\n",
        "    removed_anom = target_anomaly(scaled_df)\n",
        "    print(f\"Shape after removing target anomalies: {removed_anom.shape}\")\n",
        "\n",
        "    print(f\"Dropping infrequent 'Failure type' (<= {infrequent_threshold*100}%)...\")\n",
        "    cleaned_failure = drop_infrequent(removed_anom, threshold=infrequent_threshold)\n",
        "    print(f\"Shape after dropping infrequent failures: {cleaned_failure.shape}\")\n",
        "\n",
        "    print(\"Augmenting data using SMOTENC...\")\n",
        "    augmented_data = augment_data(cleaned_failure)\n",
        "    print(f\"Shape after augmentation: {augmented_data.shape}\")\n",
        "\n",
        "    parent_dir = os.path.dirname(output_dir)\n",
        "    if parent_dir:\n",
        "        os.makedirs(parent_dir, exist_ok=True)\n",
        "        print(f\"Parent output directory ensured: {parent_dir}\")\n",
        "    else:\n",
        "        print(f\"Warning: Output path '{output_dir}' has no parent directory. Writing to current directory.\")\n",
        "    print(f\"Writing prepared data to: {output_dir}\")\n",
        "    augmented_data.to_csv(output_dir, index=False)\n",
        "    \n",
        "    row_count = (len(augmented_data))\n",
        "    print(f'Prepared {row_count} rows of data')\n",
        "    print(augmented_data.info())\n",
        "\n",
        "    os.makedirs(os.path.dirname(scaler_full_output_path), exist_ok=True)\n",
        "    joblib.dump(scaler, scaler_full_output_path)\n",
        "    print(f\"StandardScaler saved to: {scaler_full_output_path}\")\n",
        "\n",
        "def read_data(path):\n",
        "    df = pd.read_csv(path)\n",
        "    return df\n",
        "\n",
        "def clean_data(df):\n",
        "    df = df.dropna()\n",
        "    df = df.drop_duplicates()\n",
        "    return df\n",
        "\n",
        "def rename_features(df):\n",
        "    df.rename(mapper={'Type': 'Machine type', 'Air temperature [K]': 'Air temperature',\n",
        "                      'Process temperature [K]': 'Process temperature',\n",
        "                      'Rotational speed [rpm]': 'Rotational speed',\n",
        "                      'Torque [Nm]': 'Torque',\n",
        "                      'Tool wear [min]': 'Tool wear'}, axis=1, inplace=True)\n",
        "    return df\n",
        "\n",
        "def num_to_float(df, num_cols):\n",
        "    df[num_cols] = df[num_cols].astype(float)\n",
        "    return df\n",
        "\n",
        "def drop_high_unique_cols(df, threshold):\n",
        "    init_cols = df.columns.tolist()\n",
        "    num_rows = len(df)\n",
        "    drop_cols = []\n",
        "    for col in df.columns:\n",
        "        unique_count = df[col].nunique()\n",
        "        unique_percentage = unique_count / num_rows * 100\n",
        "        if unique_percentage > threshold:\n",
        "            drop_cols.append(col)\n",
        "    df = df.drop(columns=drop_cols)\n",
        "    return df\n",
        "\n",
        "def create_failure_type(df):\n",
        "    df['Failure type'] = 'No Failure'\n",
        "    df.loc[df['TWF'] == 1, 'Failure type'] = 'TWF'\n",
        "    df.loc[df['HDF'] == 1, 'Failure type'] = 'HDF'\n",
        "    df.loc[df['PWF'] == 1, 'Failure type'] = 'PWF'\n",
        "    df.loc[df['OSF'] == 1, 'Failure type'] = 'OSF'\n",
        "    df.loc[df['RNF'] == 1, 'Failure type'] = 'RNF'\n",
        "    failure_columns = ['TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
        "    for index, row in df.iterrows():\n",
        "        if row['Failure type'] == 'No Failure' and row['Machine failure'] == 1:\n",
        "            for col in failure_columns:\n",
        "                if row[col] == 1:\n",
        "                    df.loc[index, 'Failure type'] = col\n",
        "                    break\n",
        "    df = df.drop(columns=['TWF', 'HDF', 'PWF', 'OSF', 'RNF'])\n",
        "    return df\n",
        "\n",
        "def label_enc(df):\n",
        "    machine_type_dict = {'L': 0, 'M': 1, 'H': 2}\n",
        "    machine_failure_dict = {'No Failure': 0, 'PWF': 1, 'OSF': 2, 'HDF': 3, 'TWF': 4, 'RNF': 5}\n",
        "    df['Machine type'].replace(to_replace=machine_type_dict, inplace=True)\n",
        "    df['Failure type'].replace(to_replace=machine_failure_dict, inplace=True)\n",
        "    return df\n",
        "\n",
        "def scaling_data(df, float_cols):\n",
        "    sc = StandardScaler()\n",
        "    df[float_cols] = sc.fit_transform(df[float_cols])\n",
        "    return df, sc\n",
        "\n",
        "def target_anomaly(df):\n",
        "    anomaly1 = ((df[\"Machine failure\"] == 0) & (df[\"Failure type\"] == 5))\n",
        "    df.drop(index=df.loc[anomaly1].index, inplace=True)\n",
        "    anomaly2 = ((df[\"Machine failure\"] == 1) & (df[\"Failure type\"] == 0))\n",
        "    df.drop(index=df.loc[anomaly2].index, inplace=True)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    return df\n",
        "\n",
        "def drop_infrequent(df, threshold):\n",
        "    num_rows = len(df)\n",
        "    value_counts = df['Failure type'].value_counts(normalize=True) * 100\n",
        "    infrequent_values = value_counts[value_counts <= threshold].index.tolist()\n",
        "    df = df[~df['Failure type'].isin(infrequent_values)].copy()\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    return df\n",
        "\n",
        "def augment_data(df):\n",
        "    working = df['Failure type'].value_counts()[0]\n",
        "    desired_length = round(working / 0.8)\n",
        "    spc = round((desired_length - working) / 4)\n",
        "    balance_cause = {0: working, 1: spc, 2: spc, 3: spc, 4: spc}\n",
        "    aug = SMOTENC(categorical_features=[0, 7], sampling_strategy=balance_cause, random_state=0)\n",
        "    df, _= aug.fit_resample(df, df['Failure type'])\n",
        "    return df\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--input_data\", dest='input_data', type=str, required=True,\n",
        "                        help=\"Path to the input data (can be a local path or Azure ML URI)\")\n",
        "    parser.add_argument(\"--output_data\", dest='output_data', type=str, required=True,\n",
        "                        help=\"Path to the output directory\")\n",
        "    parser.add_argument(\"--scaler_output_data\", dest='scaler_output_data', type=str, required=True,\n",
        "                        help=\"Full path for the StandardScaler object file\")\n",
        "    return parser.parse_args()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = parse_args()\n",
        "    main(args)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting src/prep-data.py\n"
        }
      ],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create command job to run the prep-data script and register the output as URI File."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import Input, Output\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.ai.ml import command\n",
        "\n",
        "prep_data = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python prep-data.py --input_data ${{inputs.raw_data}} --output_data ${{outputs.processed_data}} --scaler_output_data ${{outputs.scaler_model}}\",\n",
        "    inputs={\n",
        "        \"raw_data\": Input(type=\"uri_file\", path=\"azureml:predictive_maintenance_raw_data:1\")\n",
        "    },\n",
        "    outputs={\"processed_data\": Output(\n",
        "        type=AssetTypes.URI_FILE,\n",
        "        mode=\"rw_mount\",\n",
        "        name=\"training_data_predictive_maintenance\",\n",
        "        description=\"Training data for predictive maintenance\"),\n",
        "        \"scaler_model\": Output(\n",
        "            type=AssetTypes.URI_FILE,\n",
        "            mode=\"rw_mount\",\n",
        "            name=\"pdm_scaler\",\n",
        "            description=\"StandardScaler object for predictive maintenance features\"\n",
        "        )\n",
        "    },\n",
        "    environment=\"sklearn-env:2\",\n",
        "    compute=\"jmanuel\",\n",
        "    display_name=\"prep-data-script\",\n",
        "    experiment_name=\"prep-data\",\n",
        "    )\n",
        "\n",
        "returned_job = ml_client.create_or_update(prep_data)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n\u001b[32mUploading src (0.03 MBs): 100%|██████████| 34926/34926 [00:00<00:00, 784326.67it/s]\n\u001b[39m\n\npathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFileJobOutput'> and will be ignored\npathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFileJobOutput'> and will be ignored\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Monitor your job at https://ml.azure.com/runs/olive_gas_shhtpkv991?wsid=/subscriptions/55fc198d-597c-451e-9372-e172883e1ef0/resourcegroups/case-study-rg/workspaces/ml-intern-ws&tid=6f731b06-089d-46f3-b7a6-b11ab2f47e4c\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1748277673074
        },
        "jupyter": {
          "source_hidden": true,
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training - Binary Classifier"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {script_folder}/train-binary-model.py\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, f1_score, fbeta_score, make_scorer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import time\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import joblib\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from mlflow.models.signature import infer_signature\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "def main(args):\n",
        "    prepared_data = args.prepared_data\n",
        "\n",
        "    with mlflow.start_run():\n",
        "        client = MlflowClient()\n",
        "        run_id = mlflow.active_run().info.run_id\n",
        "\n",
        "        df = read_data(prepared_data)\n",
        "        print(\"Data loaded successfully:\")\n",
        "        print(df.info())\n",
        "\n",
        "        print(\"Splitting data...\")\n",
        "        X_train, y_train, X_val, y_val, X_test, y_test = split_data(df)\n",
        "\n",
        "        print(\"Binary task...\")\n",
        "        lr = LogisticRegression()\n",
        "        svc = SVC(probability=True)\n",
        "        xgb = XGBClassifier() \n",
        "\n",
        "        clf_binary = [lr,svc,xgb]\n",
        "        clf_str_binary = ['LR','SVC','XGB'] \n",
        "\n",
        "        lr_params_binary = {\n",
        "                'penalty': ['l2'],\n",
        "                'C': [0.01, 0.1, 1, 10], \n",
        "                'solver': ['lbfgs'], \n",
        "                'max_iter': [100, 200, 500],\n",
        "                'random_state': [0]}\n",
        "        svc_params_binary = {'C': [1, 10, 100],\n",
        "              'gamma': [0.1,1],\n",
        "              'kernel': ['rbf'],\n",
        "              'probability':[True],\n",
        "              'random_state':[0]}\n",
        "        xgb_params_binary = {'n_estimators':[300,500,700],\n",
        "              'max_depth':[5,7],\n",
        "              'learning_rate':[0.01,0.1],\n",
        "              'objective':['binary:logistic']}\n",
        "        \n",
        "        params_binary = pd.Series(data=[lr_params_binary, svc_params_binary, xgb_params_binary], index=clf_binary)\n",
        "\n",
        "        metrics_df, fitted_models, confusion_matrices = fit_base_models(clf_binary, clf_str_binary, X_train, X_val, y_train, y_val)\n",
        "        plot_model_metrics(metrics_df, \"binary_base_model_metrics.png\")\n",
        "        mlflow.log_artifact(\"binary_base_model_metrics.png\")\n",
        "\n",
        "        for name, cm in confusion_matrices.items():\n",
        "            plot_confusion_matrix(cm, ['No Failure', 'Failure'], f'confusion_matrix_binary_{name}.png')\n",
        "            mlflow.log_artifact(f'confusion_matrix_binary_{name}.png')\n",
        "\n",
        "        fitted_models_binary = {name: tune_and_fit(model, X_train, y_train, params_binary[model]) for model, name in zip(clf_binary, clf_str_binary)}\n",
        "        for name, model in fitted_models_binary.items():\n",
        "            input_example = pd.DataFrame(X_test)\n",
        "            signature = infer_signature(input_example, model.predict(X_test))\n",
        "            mlflow.sklearn.log_model(model, artifact_path=f\"models/{name}\", signature=signature)\n",
        "\n",
        "        for name in fitted_models_binary.keys():\n",
        "            model_uri = f\"runs:/{run_id}/models/{name}\"\n",
        "            registered_model_name = f\"predictive_maintenance_binary_{name.lower()}\"\n",
        "            mlflow.register_model(model_uri=model_uri, name=registered_model_name)\n",
        "            print(f\"Registered binary base model: {registered_model_name}\")\n",
        "\n",
        "        base_model_predictions_val_binary = create_base_model_predictions(fitted_models_binary, X_val)\n",
        "\n",
        "        meta_learner_binary = LogisticRegression()\n",
        "        meta_learner_binary = train_meta_learner(meta_learner_binary, base_model_predictions_val_binary, y_val)\n",
        "\n",
        "        base_model_predictions_test_binary = create_base_model_predictions(fitted_models_binary, X_test)\n",
        "        final_predictions_test_binary = meta_learner_binary.predict(base_model_predictions_test_binary)\n",
        "\n",
        "        cm_test_stacked_binary, metrics_test_stacked_binary = evaluate_stacked_model(meta_learner_binary, base_model_predictions_test_binary, y_test, final_predictions_test_binary)\n",
        "        plot_confusion_matrix(cm_test_stacked_binary, ['No Failure', 'Failure'], 'stacked_binary_confusion_matrix.png')\n",
        "        mlflow.log_artifact(\"stacked_binary_confusion_matrix.png\")\n",
        "\n",
        "        mlflow.log_metric(\"accuracy_stacked_binary\", metrics_test_stacked_binary['ACC'])\n",
        "        mlflow.log_metric(\"auc_stacked_binary\", metrics_test_stacked_binary['AUC'])\n",
        "        mlflow.log_metric(\"f2_stacked_binary\", metrics_test_stacked_binary['F2'])\n",
        "\n",
        "        mlflow.sklearn.log_model(meta_learner_binary, \"models/meta_learner\",\n",
        "                                 signature=infer_signature(base_model_predictions_test_binary, final_predictions_test_binary))\n",
        "        meta_model_uri = f\"runs:/{run_id}/models/meta_learner\"\n",
        "        meta_registered_name = \"predictive_maintenance_binary_meta_learner\"\n",
        "        mlflow.register_model(model_uri=meta_model_uri, name=meta_registered_name)\n",
        "        print(f\"Registered binary meta-learner model: {meta_registered_name}\")\n",
        "\n",
        "        y_pred_base_test_binary, cm_dict_base_test_binary, metrics_base_test_binary = predict_and_evaluate(list(fitted_models_binary.values()), X_test, y_test, list(fitted_models_binary.keys()))\n",
        "        comparison_data_binary = {\n",
        "            'Model': list(fitted_models_binary.keys()) + ['Stacked'],\n",
        "            'Accuracy': list(metrics_base_test_binary['ACC']) + [metrics_test_stacked_binary['ACC']],\n",
        "            'AUC': list(metrics_base_test_binary['AUC']) + [metrics_test_stacked_binary['AUC']],\n",
        "            'F2': list(metrics_base_test_binary['F2']) + [metrics_test_stacked_binary['F2']]\n",
        "        }\n",
        "        comparison_df_binary = pd.DataFrame(comparison_data_binary)\n",
        "        comparison_df_binary.set_index('Model', inplace=True)\n",
        "        plot_model_metrics(comparison_df_binary, \"binary_models_comparison.png\")\n",
        "        mlflow.log_artifact(\"binary_models_comparison.png\")\n",
        "\n",
        "def read_data(path):\n",
        "    df = pd.read_csv(path)\n",
        "    return df\n",
        "\n",
        "def split_data(df):\n",
        "    X = df.drop(columns=['Machine failure', 'Failure type'])\n",
        "    y = df[['Machine failure', 'Failure type']]\n",
        "    X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.1, stratify=y['Failure type'], random_state=0)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.11, stratify=y_trainval['Failure type'], random_state=0)\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "def plot_model_metrics(metrics_df, file_name):\n",
        "    metrics_df.plot(kind='bar', figsize=(10, 6))\n",
        "    plt.title('Model Evaluation Metrics')\n",
        "    plt.ylabel('Score')\n",
        "    plt.xticks(rotation=0)\n",
        "    plt.legend(title='Metric')\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(file_name)\n",
        "    plt.close()\n",
        "\n",
        "def plot_confusion_matrix(cm, labels, file_name):\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "    plt.title(file_name.replace(\".png\", \"\"))\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(file_name)\n",
        "    plt.close()\n",
        "\n",
        "def eval_preds(model, X, y_true):\n",
        "    y_true_binary = y_true['Machine failure']\n",
        "    y_pred = model.predict(X)\n",
        "    cm = confusion_matrix(y_true_binary, y_pred)\n",
        "    proba = model.predict_proba(X)[:, 1]\n",
        "    metrics = pd.Series(dtype='float64')\n",
        "    metrics['ACC'] = accuracy_score(y_true_binary, y_pred)\n",
        "    metrics['AUC'] = roc_auc_score(y_true_binary, proba)\n",
        "    metrics['F1'] = f1_score(y_true_binary, y_pred, pos_label=1)\n",
        "    metrics['F2'] = fbeta_score(y_true_binary, y_pred, pos_label=1, beta=2)\n",
        "    return cm, round(metrics, 3)\n",
        "\n",
        "def fit_base_models(clf_list, clf_names, X_train, X_val, y_train, y_val):\n",
        "    metrics_df = pd.DataFrame(columns=clf_names)\n",
        "    fitted_models = {}\n",
        "    confusion_matrices = {}\n",
        "    for model, name in zip(clf_list, clf_names):\n",
        "        model.fit(X_train, y_train['Machine failure'])\n",
        "        fitted_models[name] = model\n",
        "        cm, scores = eval_preds(model, X_val, y_val)\n",
        "        metrics_df[name] = scores\n",
        "        confusion_matrices[name] = cm\n",
        "    return metrics_df.T, fitted_models, confusion_matrices\n",
        "\n",
        "def tune_and_fit(clf, X, y, params):\n",
        "    scorer = make_scorer(fbeta_score, pos_label=1, beta=2)\n",
        "    grid_model = GridSearchCV(clf, param_grid=params, cv=5, scoring=scorer)\n",
        "    grid_model.fit(X, y['Machine failure'])\n",
        "    print(f'Best params for {clf.__class__.__name__}: {grid_model.best_params_}')\n",
        "    return grid_model\n",
        "\n",
        "def create_base_model_predictions(fitted_models, X):\n",
        "    preds = {model_name: model.predict_proba(X)[:, 1] for model_name, model in fitted_models.items()}\n",
        "    return pd.DataFrame(preds)\n",
        "\n",
        "def train_meta_learner(meta_learner, base_predictions, y_true):\n",
        "    meta_learner.fit(base_predictions, y_true['Machine failure'])\n",
        "    return meta_learner\n",
        "\n",
        "def evaluate_stacked_model(meta_learner, base_predictions, y_true, y_pred):\n",
        "    cm, metrics = eval_preds(meta_learner, base_predictions, y_true)\n",
        "    print(\"--- Stacked Model Test Set Evaluation (Binary) ---\")\n",
        "    print(metrics)\n",
        "    return cm, metrics\n",
        "\n",
        "def predict_and_evaluate(fitted_models, X, y_true, clf_str):\n",
        "    cm_dict = {}\n",
        "    metrics_df = pd.DataFrame(columns=clf_str)\n",
        "    y_pred_df = pd.DataFrame(columns=clf_str)\n",
        "    for fit_model, model_name in zip(fitted_models, clf_str):\n",
        "        y_pred = fit_model.predict(X)\n",
        "        y_pred_df[model_name] = y_pred\n",
        "        cm, scores = eval_preds(fit_model, X, y_true)\n",
        "        cm_dict[model_name] = cm\n",
        "        metrics_df[model_name] = scores\n",
        "    return y_pred_df, cm_dict, metrics_df.T\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--prepared_data\", type=str, help=\"Path to the prepared training dataset\")\n",
        "    return parser.parse_args()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = parse_args()\n",
        "    main(args)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting src/train-binary-model.py\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1747325457042
        },
        "jupyter": {
          "source_hidden": true
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a command job that trains the binary models and registers the models as MLModel"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import Input, Output\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.ai.ml import command\n",
        "\n",
        "train_binary_model = command(\n",
        "   code=\"./src\",\n",
        "   command=\"python train-binary-model.py --prepared_data ${{inputs.training_data}}\",\n",
        "   inputs={\"training_data\": Input(type=\"uri_file\", path=\"azureml:training_data_predictive_maintenance:9\")},\n",
        "   environment=\"sklearn-env:2\",\n",
        "   compute=\"jmanuel\",\n",
        "   display_name=\"Train Binary Model\",\n",
        "   experiment_name=\"binary-training\",\n",
        ")\n",
        "\n",
        "returned_job = ml_client.create_or_update(train_binary_model)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Monitor your job at https://ml.azure.com/runs/blue_watch_8bf8rm46j9?wsid=/subscriptions/55fc198d-597c-451e-9372-e172883e1ef0/resourcegroups/case-study-rg/workspaces/ml-intern-ws&tid=6f731b06-089d-46f3-b7a6-b11ab2f47e4c\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1748268397984
        },
        "jupyter": {
          "source_hidden": true
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training - Multi-Class Classifier"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {script_folder}/train-multiclass-model.py\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, fbeta_score, make_scorer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import time\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import joblib\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from mlflow.models.signature import infer_signature\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "def main(args):\n",
        "    prepared_data = args.prepared_data\n",
        "\n",
        "    with mlflow.start_run():\n",
        "        client = MlflowClient()\n",
        "        run_id = mlflow.active_run().info.run_id\n",
        "\n",
        "        df = read_data(prepared_data)\n",
        "        print(\"Data loaded successfully:\")\n",
        "        print(df.info())\n",
        "\n",
        "        print(\"Splitting data...\")\n",
        "        X_train, y_train, X_val, y_val, X_test, y_test = split_data(df)\n",
        "\n",
        "        print(\"Defining multi-class models...\")\n",
        "        lr = LogisticRegression()\n",
        "        svc = SVC(decision_function_shape='ovr', probability=True)\n",
        "        xgb = XGBClassifier()\n",
        "\n",
        "        clf_multi = [lr, svc, xgb]\n",
        "        clf_str_multi = ['LR', 'SVC', 'XGB']\n",
        "\n",
        "        print(\"Defining hyperparameters...\")\n",
        "        lr_params_multi = {\n",
        "            'penalty': ['l2'],\n",
        "            'C': [0.01, 0.1, 1, 10],\n",
        "            'solver': ['lbfgs'],\n",
        "            'multi_class': ['multinomial'],\n",
        "            'max_iter': [100, 200, 500],\n",
        "            'random_state': [0]}\n",
        "        svc_params_multi = {\n",
        "            'C': [1, 10, 100],\n",
        "            'gamma': [0.1, 1],\n",
        "            'kernel': ['rbf'],\n",
        "            'random_state': [0]}\n",
        "        xgb_params_multi  = {'n_estimators':[100,300,500],\n",
        "              'max_depth':[5,7,10],\n",
        "              'learning_rate':[0.01,0.1],\n",
        "              'objective':['multi:softprob']}\n",
        "        params_multi = pd.Series(data=[lr_params_multi, svc_params_multi, xgb_params_multi], index=clf_multi)\n",
        "\n",
        "        failure_labels = ['No Failure', 'PWF', 'OSF', 'HDF', 'TWF']\n",
        "        metrics_df, fitted_models, confusion_matrices = fit_base_models(clf_multi, clf_str_multi, X_train, X_val, y_train, y_val, failure_labels)\n",
        "        print(f\"Base Model Metrics: {metrics_df}\")\n",
        "        plot_model_metrics(metrics_df, \"multiclass_base_model_metrics.png\")\n",
        "        mlflow.log_artifact(\"multiclass_base_model_metrics.png\")\n",
        "\n",
        "        for name, cm in confusion_matrices.items():\n",
        "            plot_confusion_matrix(cm, failure_labels, f'confusion_matrix_multi_{name}.png')\n",
        "            mlflow.log_artifact(f'confusion_matrix_multi_{name}.png')\n",
        "\n",
        "        failure_label_map = {0: 'NoFailure', 1: 'PWF', 2: 'OSF', 3: 'HDF', 4: 'TWF',}\n",
        "        print(\"Tuning hyperparameters...\")\n",
        "        fitted_models_multi = {name: tune_and_fit(model, X_train, y_train, params_multi[model]) for model, name in zip(clf_multi, clf_str_multi)}\n",
        "        for name, model in fitted_models_multi.items():\n",
        "            input_example = pd.DataFrame(X_test)\n",
        "            signature = infer_signature(input_example, model.predict(X_test))\n",
        "            mlflow.sklearn.log_model(model, artifact_path=f\"models/{name}\", signature=signature)\n",
        "\n",
        "        for name in fitted_models_multi.keys():\n",
        "            model_uri = f\"runs:/{run_id}/models/{name}\"\n",
        "            registered_model_name = f\"predictive_maintenance_multi_{name.lower()}\"\n",
        "            mlflow.register_model(model_uri=model_uri, name=registered_model_name)\n",
        "            print(f\"Registered multiclass model: {registered_model_name}\")\n",
        "\n",
        "        print(\"Creating predictions...\")\n",
        "        base_model_predictions_val_multi = create_base_model_predictions(fitted_models_multi, X_val, failure_label_map)\n",
        "\n",
        "        print(\"Training meta learner...\")\n",
        "        meta_learner_multi = LogisticRegression()\n",
        "        meta_learner_multi = train_meta_learner(meta_learner_multi, base_model_predictions_val_multi, y_val,)\n",
        "        base_model_predictions_test_multi = create_base_model_predictions(fitted_models_multi, X_test, failure_label_map)\n",
        "\n",
        "        final_predictions_test_multi = meta_learner_multi.predict(base_model_predictions_test_multi)\n",
        "        cm_test_stacked_multi, metrics_test_stacked_multi = evaluate_stacked_model(meta_learner_multi, base_model_predictions_test_multi, y_test, final_predictions_test_multi, failure_labels)\n",
        "        plot_confusion_matrix(cm_test_stacked_multi, failure_labels, f'stacked_multi_confusion_matrix.png')\n",
        "        mlflow.log_artifact(\"stacked_multi_confusion_matrix.png\")\n",
        "\n",
        "        mlflow.log_metric(\"accuracy_stacked_multi\", metrics_test_stacked_multi['ACC'])\n",
        "        mlflow.log_metric(\"f2_stacked_multi\", metrics_test_stacked_multi['F2'])\n",
        "\n",
        "        mlflow.sklearn.log_model(meta_learner_multi, \"models/meta_learner\",\n",
        "                                 signature=infer_signature(base_model_predictions_test_multi, final_predictions_test_multi))\n",
        "        meta_model_uri = f\"runs:/{run_id}/models/meta_learner\"\n",
        "        meta_registered_name = \"predictive_maintenance_multiclass_meta_learner\"\n",
        "        mlflow.register_model(model_uri=meta_model_uri, name=meta_registered_name)\n",
        "        print(f\"Registered multiclass meta-learner model: {meta_registered_name}\")\n",
        "\n",
        "        y_pred_base_test_multi, cm_dict_base_test_multi, metrics_base_test_multi = predict_and_evaluate(list(fitted_models_multi.values()), X_test, y_test, list(fitted_models_multi.keys()), failure_labels)\n",
        "        comparison_data_multi = {\n",
        "            'Model': list(fitted_models_multi.keys()) + ['Stacked'],\n",
        "            'Accuracy': list(metrics_base_test_multi['ACC']) + [metrics_test_stacked_multi['ACC']],\n",
        "            'F2': list(metrics_base_test_multi['F2']) + [metrics_test_stacked_multi['F2']]\n",
        "        }\n",
        "        comparison_df_multi = pd.DataFrame(comparison_data_multi)\n",
        "        print(comparison_df_multi)\n",
        "        comparison_df_multi.set_index('Model', inplace=True)\n",
        "        plot_model_metrics(comparison_df_multi, \"multiclass_models_comparison.png\")\n",
        "        mlflow.log_artifact(\"multiclass_models_comparison.png\")\n",
        "\n",
        "def read_data(path):\n",
        "    df = pd.read_csv(path)\n",
        "    return df\n",
        "\n",
        "def split_data(df):\n",
        "    X = df.drop(columns=['Machine failure', 'Failure type'])\n",
        "    y = df[['Machine failure', 'Failure type']]\n",
        "    X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.1, stratify=y['Failure type'], random_state=0)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.11, stratify=y_trainval['Failure type'], random_state=0)\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "def plot_model_metrics(metrics_df, file_name):\n",
        "    metrics_df.plot(kind='bar', figsize=(10, 6))\n",
        "    plt.title('Model Evaluation Metrics')\n",
        "    plt.ylabel('Score')\n",
        "    plt.xticks(rotation=0)\n",
        "    plt.legend(title='Metric')\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(file_name)\n",
        "    plt.close()\n",
        "\n",
        "def plot_confusion_matrix(cm, labels, file_name):\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "    plt.title(file_name.replace(\".png\", \"\"))\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(file_name)\n",
        "    plt.close()\n",
        "\n",
        "def eval_preds(model, X, y_true, failure_labels):\n",
        "    y_true_multi = y_true['Failure type']\n",
        "    y_pred = model.predict(X)\n",
        "    cm = confusion_matrix(y_true_multi, y_pred, labels=range(len(failure_labels)))\n",
        "    metrics = pd.Series(dtype='float64')\n",
        "    metrics['ACC'] = accuracy_score(y_true_multi, y_pred)\n",
        "    metrics['F1'] = f1_score(y_true_multi, y_pred, average='weighted')\n",
        "    metrics['F2'] = fbeta_score(y_true_multi, y_pred, beta=2, average='weighted')\n",
        "\n",
        "    return cm, round(metrics, 3)\n",
        "\n",
        "def fit_base_models(clf_list, clf_names, X_train, X_val, y_train, y_val, failure_labels):\n",
        "    metrics_df = pd.DataFrame(columns=clf_names)\n",
        "    fitted_models = {}\n",
        "    confusion_matrices = {}\n",
        "    for model, name in zip(clf_list, clf_names):\n",
        "        model.fit(X_train, y_train['Failure type'])\n",
        "        fitted_models[name] = model\n",
        "        cm, scores = eval_preds(model, X_val, y_val, failure_labels)\n",
        "        metrics_df[name] = scores\n",
        "        confusion_matrices[name] = cm\n",
        "    return metrics_df.T, fitted_models, confusion_matrices\n",
        "\n",
        "def tune_and_fit(clf, X, y, params):\n",
        "    scorer =  make_scorer(fbeta_score, beta=2, average='weighted')\n",
        "    start_time = time.time()\n",
        "    grid_model = GridSearchCV(clf, param_grid=params, cv=5, scoring=scorer)\n",
        "    grid_model.fit(X, y['Failure type'])\n",
        "    print(f'Best params for {clf.__class__.__name__}: {grid_model.best_params_}')\n",
        "    train_time = time.time() - start_time\n",
        "    mins = int(train_time // 60)\n",
        "    print(f'Training time: {mins}m {round(train_time - mins * 60)}s')\n",
        "    return grid_model\n",
        "\n",
        "def create_base_model_predictions(fitted_models, X, failure_label_map):\n",
        "    predictions = pd.DataFrame()\n",
        "    for model_name, model in fitted_models.items():\n",
        "        preds = model.predict_proba(X)\n",
        "        preds = preds.astype(np.float64)\n",
        "\n",
        "        for i in range(preds.shape[1]):\n",
        "            class_name = failure_label_map.get(i, f'class_{i}')\n",
        "            predictions[f'{model_name}_class_{i}'] = preds[:, i]\n",
        "    return predictions\n",
        "\n",
        "def train_meta_learner(meta_learner, base_predictions, y_true):\n",
        "    meta_learner.fit(base_predictions, y_true['Failure type'])\n",
        "    return meta_learner\n",
        "\n",
        "def evaluate_stacked_model(meta_learner, base_predictions, y_true, y_pred, failure_labels):\n",
        "    cm, metrics = eval_preds(meta_learner, base_predictions, y_true, failure_labels)\n",
        "    print(\"--- Stacked Model Test Set Evaluation (Multi-class) ---\")\n",
        "    print(metrics)\n",
        "    return cm, metrics\n",
        "\n",
        "def predict_and_evaluate(fitted_models, X, y_true, clf_str, failure_labels):\n",
        "    cm_dict = {}\n",
        "    metrics_df = pd.DataFrame(columns=clf_str)\n",
        "    y_pred_df = pd.DataFrame(columns=clf_str)\n",
        "    for fit_model, model_name in zip(fitted_models, clf_str):\n",
        "        y_pred = fit_model.predict(X)\n",
        "        y_pred_df[model_name] = y_pred\n",
        "        cm, scores = eval_preds(fit_model, X, y_true, failure_labels)\n",
        "        cm_dict[model_name] = cm\n",
        "        metrics_df[model_name] = scores\n",
        "    return y_pred_df, cm_dict, metrics_df.T\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--prepared_data\", type=str, help=\"Path to the prepared training dataset\")\n",
        "    return parser.parse_args()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = parse_args()\n",
        "    main(args)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting src/train-multiclass-model.py\n"
        }
      ],
      "execution_count": 44,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a command job that trains the multi-class models and registers the models as MLModel"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import Input, Output\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.ai.ml import command\n",
        "\n",
        "train_multi_model = command(\n",
        "   code=\"./src\",\n",
        "   command=\"python train-multiclass-model.py --prepared_data ${{inputs.training_data}}\",\n",
        "   inputs={\"training_data\": Input(type=\"uri_file\", path=\"azureml:training_data_predictive_maintenance:9\")},\n",
        "   environment=\"sklearn-env:3\",\n",
        "   compute=\"enddpl\",\n",
        "   display_name=\"Train Multi-Class Model\",\n",
        "   experiment_name=\"multi-class-training\",\n",
        ")\n",
        "\n",
        "returned_job = ml_client.create_or_update(train_multi_model)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Monitor your job at https://ml.azure.com/runs/sleepy_brain_708x5qkl6s?wsid=/subscriptions/55fc198d-597c-451e-9372-e172883e1ef0/resourcegroups/case-study-rg/workspaces/ml-intern-ws&tid=6f731b06-089d-46f3-b7a6-b11ab2f47e4c\n"
        }
      ],
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1748363791312
        },
        "jupyter": {
          "source_hidden": true
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Wrapper"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {script_folder}/custom_pdm_model.py\n",
        "import json\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import mlflow.pyfunc\n",
        "from typing import Dict\n",
        "\n",
        "class PredictiveMaintenanceModel(mlflow.pyfunc.PythonModel):\n",
        "\n",
        "    def load_context(self, context):\n",
        "        # Load scaler\n",
        "        self.scaler = joblib.load(context.artifacts[\"scaler\"])\n",
        "\n",
        "        # Load binary base models\n",
        "        self.binary_models = [\n",
        "            mlflow.sklearn.load_model(context.artifacts[\"binary_lr\"]),\n",
        "            mlflow.sklearn.load_model(context.artifacts[\"binary_xgb\"]),\n",
        "            mlflow.sklearn.load_model(context.artifacts[\"binary_svc\"])\n",
        "        ]\n",
        "        self.binary_meta = mlflow.pyfunc.load_model(context.artifacts[\"binary_meta\"])\n",
        "\n",
        "        # Load multiclass base models\n",
        "        self.multiclass_models = [\n",
        "            mlflow.sklearn.load_model(context.artifacts[\"multi_lr\"]),\n",
        "            mlflow.sklearn.load_model(context.artifacts[\"multi_xgb\"]),\n",
        "            mlflow.sklearn.load_model(context.artifacts[\"multi_svc\"])\n",
        "        ]\n",
        "        self.multiclass_meta = mlflow.pyfunc.load_model(context.artifacts[\"multi_meta\"])\n",
        "\n",
        "    def preprocess(self, input_data: Dict):\n",
        "        df = pd.DataFrame([input_data])\n",
        "        df[\"Machine type\"] = df[\"Machine type\"].map({\"L\": 0, \"M\": 1, \"H\": 2})\n",
        "\n",
        "        float_cols = ['Air temperature', 'Process temperature', 'Rotational speed', 'Torque', 'Tool wear']\n",
        "        df[float_cols] = df[float_cols].astype(float)\n",
        "        df[float_cols] = self.scaler.transform(df[float_cols])\n",
        "\n",
        "        return df[['Machine type'] + float_cols]\n",
        "\n",
        "    def predict(self, context, model_input):\n",
        "        if isinstance(model_input, dict):\n",
        "            parsed_input_dict = model_input\n",
        "        elif isinstance(model_input, pd.DataFrame):\n",
        "            if not model_input.empty:\n",
        "                parsed_input_dict = model_input.iloc[0].to_dict()\n",
        "            else:\n",
        "                return {\"error\": \"Invalid input format. Received an empty DataFrame.\"}\n",
        "        else:\n",
        "            return {\"error\": \"Invalid input format. Expected dictionary or DataFrame.\"}\n",
        "\n",
        "        # Validate input\n",
        "        required_keys = ['Machine type', 'Air temperature', 'Process temperature', 'Rotational speed', 'Torque', 'Tool wear']\n",
        "        if not all(k in parsed_input_dict for k in required_keys):\n",
        "            return {\"error\": f\"Missing one or more required keys in input: {required_keys}. Received keys: {list(parsed_input_dict.keys())}\"}\n",
        "\n",
        "        X_processed = self.preprocess(parsed_input_dict)\n",
        "\n",
        "        # Predict with binary models\n",
        "        binary_probs = np.array([m.predict(X_processed) for m in self.binary_models]).reshape(1, -1)\n",
        "        binary_input = pd.DataFrame({\n",
        "            \"LR\": binary_probs[0, 0],\n",
        "            \"XGB\": binary_probs[0, 1],\n",
        "            \"SVC\": binary_probs[0, 2]\n",
        "        }, index=[0])\n",
        "\n",
        "        failure_pred = self.binary_meta.predict(binary_input)[0]\n",
        "        if failure_pred == 0:\n",
        "            return {\"failure\": \"no\", \"failure_type\": None}\n",
        "\n",
        "        # Multiclass prediction\n",
        "        lr_probs = self.multiclass_models[0].predict_proba(X_processed).flatten()\n",
        "        xgb_probs = self.multiclass_models[1].predict_proba(X_processed).flatten()\n",
        "        svc_probs = self.multiclass_models[2].predict_proba(X_processed).flatten()\n",
        "\n",
        "        # Concatenate and reshape\n",
        "        # This will naturally result in float64 for all if base model outputs are float64\n",
        "        probs_concat = np.concatenate([\n",
        "            lr_probs,\n",
        "            xgb_probs, # This will now be float64\n",
        "            svc_probs\n",
        "        ])\n",
        "\n",
        "        assert probs_concat.shape == (15,), f\"Expected 15 features, got {probs_concat.shape}\"\n",
        "\n",
        "        multiclass_input = pd.DataFrame([probs_concat], columns=[\n",
        "            \"LR_class_0\", \"LR_class_1\", \"LR_class_2\", \"LR_class_3\", \"LR_class_4\",\n",
        "            \"XGB_class_0\", \"XGB_class_1\", \"XGB_class_2\", \"XGB_class_3\", \"XGB_class_4\",\n",
        "            \"SVC_class_0\", \"SVC_class_1\", \"SVC_class_2\", \"SVC_class_3\", \"SVC_class_4\",\n",
        "        ])\n",
        "\n",
        "        multiclass_result = self.multiclass_meta.predict(multiclass_input)[0]\n",
        "        failure_types = {\n",
        "            0: \"Power Failure\",\n",
        "            1: \"Overstrain Failure\",\n",
        "            2: \"Heat Dissipation Failure\",\n",
        "            3: \"Tool Wear Failure\"\n",
        "        }\n",
        "\n",
        "        return {\"failure\": \"yes\", \"failure_type\": failure_types.get(multiclass_result, \"Unknown\")}"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting src/custom_pdm_model.py\n"
        }
      ],
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "source_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import sys\n",
        "import os\n",
        "print(\"Current working directory:\", os.getcwd())\n",
        "sys.path.append(os.path.abspath('./src'))\n",
        "\n",
        "from custom_pdm_model import PredictiveMaintenanceModel\n",
        "\n",
        "mlflow.set_experiment(\"PredictiveMaintenance\")\n",
        "\n",
        "with mlflow.start_run():\n",
        "    mlflow.pyfunc.log_model(\n",
        "        artifact_path=\"predictive_maintenance_model\",\n",
        "        python_model=PredictiveMaintenanceModel(),\n",
        "        artifacts={\n",
        "            \"scaler\": \"./scaler_artifact/scaler_model\",\n",
        "            \"binary_lr\": \"./model_artifact/binary_lr\",\n",
        "            \"binary_xgb\": \"./model_artifact/binary_xgb\",\n",
        "            \"binary_svc\": \"./model_artifact/binary_svc\",\n",
        "            \"binary_meta\": \"./model_artifact/binary_meta\",\n",
        "            \"multi_lr\": \"./model_artifact/multi_lr\",\n",
        "            \"multi_xgb\": \"./model_artifact/multi_xgb\",\n",
        "            \"multi_svc\": \"./model_artifact/multi_svc\",\n",
        "            \"multi_meta\": \"./model_artifact/multi_meta\"\n",
        "        },\n",
        "        conda_env=\"./env/conda.yaml\",\n",
        "        code_path=[\"./src/custom_pdm_model.py\"],\n",
        "        registered_model_name=\"predictive_maintenance_custom_model\"\n",
        "    )\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Current working directory: /mnt/batch/tasks/shared/LS_root/mounts/clusters/jmanuel/code/Users/jemima.simone.manuel/predictive-maintenance\n🏃 View run tough_rat_nxflsmsr at: https://southeastasia.api.azureml.ms/mlflow/v2.0/subscriptions/55fc198d-597c-451e-9372-e172883e1ef0/resourceGroups/case-study-rg/providers/Microsoft.MachineLearningServices/workspaces/ml-intern-ws/#/experiments/638110aa-645f-4f19-aa6c-5e211972a624/runs/74d5247a-5eed-4a6a-a83f-457c1f8bba1a\n🧪 View experiment at: https://southeastasia.api.azureml.ms/mlflow/v2.0/subscriptions/55fc198d-597c-451e-9372-e172883e1ef0/resourceGroups/case-study-rg/providers/Microsoft.MachineLearningServices/workspaces/ml-intern-ws/#/experiments/638110aa-645f-4f19-aa6c-5e211972a624\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:2995: UserWarning: The `code_path` argument is replaced by `code_paths` and is deprecated as of MLflow version 2.12.0. This argument will be removed in a future release of MLflow.\n  warnings.warn(\nDownloading artifacts: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s]\nDownloading artifacts: 100%|██████████| 8/8 [00:00<00:00, 52.27it/s]\nDownloading artifacts: 100%|██████████| 8/8 [00:00<00:00, 61.80it/s]\nDownloading artifacts: 100%|██████████| 8/8 [00:00<00:00, 83.11it/s]\nDownloading artifacts: 100%|██████████| 8/8 [00:00<00:00, 87.95it/s]\nDownloading artifacts: 100%|██████████| 8/8 [00:00<00:00, 39.58it/s]\nDownloading artifacts: 100%|██████████| 6/6 [00:00<00:00, 20.35it/s]\nDownloading artifacts: 100%|██████████| 8/8 [00:00<00:00, 77.29it/s]\nDownloading artifacts: 100%|██████████| 8/8 [00:00<00:00, 47.21it/s]\n2025/05/27 19:52:57 WARNING mlflow.utils.requirements_utils: Detected one or more mismatches between the model's dependencies and the current Python environment:\n - mlflow (current: 2.21.3, required: mlflow==2.17.2)\n - azureml-inference-server-http (current: uninstalled, required: azureml-inference-server-http)\nTo fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n\u001b[31m2025/05/27 19:52:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\nRegistered model 'predictive_maintenance_custom_model' already exists. Creating a new version of this model...\n2025/05/27 19:53:03 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: predictive_maintenance_custom_model, version 16\nCreated version '16' of model 'predictive_maintenance_custom_model'.\n"
        }
      ],
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1748375584405
        },
        "jupyter": {
          "source_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow.pyfunc\n",
        "\n",
        "model_uri = \"models:/predictive_maintenance_custom_model/16\"\n",
        "loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "sample_input = {\n",
        "    \"Machine type\": \"L\",\n",
        "    \"Air temperature\": 298.5,\n",
        "    \"Process temperature\": 310.2,\n",
        "    \"Rotational speed\": 2861.0,\n",
        "    \"Torque\": 4.0,\n",
        "    \"Tool wear\": 143.0\n",
        "}\n",
        "\n",
        "result = loaded_model.predict(sample_input)\n",
        "print(\"Prediction result:\")\n",
        "print(result)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Downloading artifacts: 100%|██████████| 69/69 [00:03<00:00, 19.22it/s]  \n2025/05/27 19:53:29 WARNING mlflow.utils.requirements_utils: Detected one or more mismatches between the model's dependencies and the current Python environment:\n - mlflow (current: 2.21.3, required: mlflow==2.17.2)\n - azureml-inference-server-http (current: uninstalled, required: azureml-inference-server-http)\nTo fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.3.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\nhttps://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n  warnings.warn(\n"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "Can't get attribute '_PredictScorer' on <module 'sklearn.metrics._scorer' from '/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py'>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[39], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyfunc\u001b[39;00m\n\u001b[1;32m      3\u001b[0m model_uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels:/predictive_maintenance_custom_model/16\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      8\u001b[0m sample_input \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMachine type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAir temperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m298.5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTool wear\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m143.0\u001b[39m\n\u001b[1;32m     15\u001b[0m }\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/tracing/provider.py:422\u001b[0m, in \u001b[0;36mtrace_disabled.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m disable()\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 422\u001b[0m     is_func_called, result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    424\u001b[0m     enable()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:1125\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_uri, suppress_warnings, dst_path, model_config)\u001b[0m\n\u001b[1;32m   1123\u001b[0m         model_impl \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(conf[MAIN])\u001b[38;5;241m.\u001b[39m_load_pyfunc(data_path, model_config)\n\u001b[1;32m   1124\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1125\u001b[0m         model_impl \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mMAIN\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pyfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;66;03m# This error message is particularly for the case when the error is caused by module\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;66;03m# \"databricks.feature_store.mlflow_model\". But depending on the environment, the offending\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# module might be \"databricks\", \"databricks.feature_store\" or full package. So we will\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# raise the error with the following note if \"databricks\" presents in the error. All non-\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m# databricks module errors will just be re-raised.\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m conf[MAIN] \u001b[38;5;241m==\u001b[39m _DATABRICKS_FS_LOADER_MODULE \u001b[38;5;129;01mand\u001b[39;00m e\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatabricks\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/pyfunc/model.py:1051\u001b[0m, in \u001b[0;36m_load_pyfunc\u001b[0;34m(model_path, model_config)\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_load_pyfunc\u001b[39m(model_path: \u001b[38;5;28mstr\u001b[39m, model_config: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1051\u001b[0m     context, python_model, signature \u001b[38;5;241m=\u001b[39m \u001b[43m_load_context_model_and_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _PythonModelPyfuncWrapper(\n\u001b[1;32m   1053\u001b[0m         python_model\u001b[38;5;241m=\u001b[39mpython_model,\n\u001b[1;32m   1054\u001b[0m         context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m   1055\u001b[0m         signature\u001b[38;5;241m=\u001b[39msignature,\n\u001b[1;32m   1056\u001b[0m     )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/pyfunc/model.py:1045\u001b[0m, in \u001b[0;36m_load_context_model_and_signature\u001b[0;34m(model_path, model_config)\u001b[0m\n\u001b[1;32m   1040\u001b[0m     artifacts[saved_artifact_name] \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m   1041\u001b[0m         model_path, saved_artifact_info[CONFIG_KEY_ARTIFACT_RELATIVE_PATH]\n\u001b[1;32m   1042\u001b[0m     )\n\u001b[1;32m   1044\u001b[0m context \u001b[38;5;241m=\u001b[39m PythonModelContext(artifacts\u001b[38;5;241m=\u001b[39martifacts, model_config\u001b[38;5;241m=\u001b[39mmodel_config)\n\u001b[0;32m-> 1045\u001b[0m \u001b[43mpython_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m context, python_model, signature\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/jmanuel/code/Users/jemima.simone.manuel/predictive-maintenance/src/custom_pdm_model.py:16\u001b[0m, in \u001b[0;36mPredictiveMaintenanceModel.load_context\u001b[0;34m(self, context)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(context\u001b[38;5;241m.\u001b[39martifacts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Load binary base models\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary_models \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 16\u001b[0m     \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msklearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43martifacts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbinary_lr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     17\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39msklearn\u001b[38;5;241m.\u001b[39mload_model(context\u001b[38;5;241m.\u001b[39martifacts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_xgb\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m     18\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39msklearn\u001b[38;5;241m.\u001b[39mload_model(context\u001b[38;5;241m.\u001b[39martifacts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_svc\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     19\u001b[0m ]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary_meta \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mpyfunc\u001b[38;5;241m.\u001b[39mload_model(context\u001b[38;5;241m.\u001b[39martifacts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_meta\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Load multiclass base models\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/sklearn/__init__.py:638\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_uri, dst_path)\u001b[0m\n\u001b[1;32m    636\u001b[0m sklearn_model_artifacts_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(local_model_path, flavor_conf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpickled_model\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    637\u001b[0m serialization_format \u001b[38;5;241m=\u001b[39m flavor_conf\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_format\u001b[39m\u001b[38;5;124m\"\u001b[39m, SERIALIZATION_FORMAT_PICKLE)\n\u001b[0;32m--> 638\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_model_from_local_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msklearn_model_artifacts_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserialization_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserialization_format\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/sklearn/__init__.py:457\u001b[0m, in \u001b[0;36m_load_model_from_local_file\u001b[0;34m(path, serialization_format)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m serialization_format \u001b[38;5;241m==\u001b[39m SERIALIZATION_FORMAT_CLOUDPICKLE:\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcloudpickle\u001b[39;00m\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcloudpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute '_PredictScorer' on <module 'sklearn.metrics._scorer' from '/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py'>"
          ]
        }
      ],
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1748375613805
        },
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": true
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create scripts for prediction flow of the models"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {script_folder}/score.py\n",
        "import os\n",
        "import json\n",
        "import logging\n",
        "import pandas as pd\n",
        "import mlflow.pyfunc\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "model = None\n",
        "\n",
        "def init():\n",
        "    global model\n",
        "\n",
        "    try:\n",
        "        base_model_dir = os.getenv(\"AZUREML_MODEL_DIR\")\n",
        "\n",
        "        mlflow_model_path = os.path.join(base_model_dir, \"predictive_maintenance_model\")\n",
        "\n",
        "        logging.info(f\"Attempting to load MLflow model from: {mlflow_model_path}\")\n",
        "\n",
        "        model = mlflow.pyfunc.load_model(mlflow_model_path)\n",
        "\n",
        "        logging.info(\"Model loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error loading model: {e}\")\n",
        "        raise\n",
        "\n",
        "def run(raw_data):\n",
        "    try:\n",
        "        logging.info(\"Received request data.\")\n",
        "\n",
        "        if isinstance(raw_data, str):\n",
        "            data = json.loads(raw_data)\n",
        "        elif isinstance(raw_data, dict):\n",
        "            data = raw_data\n",
        "        else:\n",
        "            return json.dumps({\"error\": \"Invalid input format. Expected JSON string or dictionary.\"})\n",
        "\n",
        "        result = model.predict(data)\n",
        "\n",
        "        logging.info(\"Prediction successful.\")\n",
        "        return json.dumps(result)\n",
        "    except Exception as e:\n",
        "        error_message = f\"Error during inference: {e}\"\n",
        "        logging.error(error_message)\n",
        "        return json.dumps({\"error\": error_message})"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting src/score.py\n"
        }
      ],
      "execution_count": 49,
      "metadata": {
        "gather": {
          "logged": 1748372279381
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Endpoint"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import ManagedOnlineEndpoint\n",
        "import datetime\n",
        "\n",
        "online_endpoint_name = \"pdm-stacked-model\"\n",
        "\n",
        "# create an online endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=online_endpoint_name,\n",
        "    description=\"Online endpoint for Stacked Predictive Maintenance model\",\n",
        "    auth_mode=\"key\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1748375153152
        },
        "jupyter": {
          "source_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.begin_create_or_update(endpoint).result()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {
            "text/plain": "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://pdm-stacked-model.southeastasia.inference.ml.azure.com/score', 'openapi_uri': 'https://pdm-stacked-model.southeastasia.inference.ml.azure.com/swagger.json', 'name': 'pdm-stacked-model', 'description': 'Online endpoint for Stacked Predictive Maintenance model', 'tags': {}, 'properties': {'createdBy': 'JEMIMA SIMONE MANUEL', 'createdAt': '2025-05-27T19:45:56.179950+0000', 'lastModifiedAt': '2025-05-27T19:45:56.179950+0000', 'azureml.onlineendpointid': '/subscriptions/55fc198d-597c-451e-9372-e172883e1ef0/resourcegroups/case-study-rg/providers/microsoft.machinelearningservices/workspaces/ml-intern-ws/onlineendpoints/pdm-stacked-model', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/55fc198d-597c-451e-9372-e172883e1ef0/providers/Microsoft.MachineLearningServices/locations/southeastasia/mfeOperationsStatus/oeidp:94050ec3-7333-45e5-8cc0-7313ec07b6be:aaf19798-9c14-454f-ab66-d55122613d48?api-version=2022-02-01-preview'}, 'print_as_yaml': False, 'id': '/subscriptions/55fc198d-597c-451e-9372-e172883e1ef0/resourceGroups/case-study-rg/providers/Microsoft.MachineLearningServices/workspaces/ml-intern-ws/onlineEndpoints/pdm-stacked-model', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/jmanuel/code/Users/jemima.simone.manuel/predictive-maintenance', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7d90992bacb0>, 'auth_mode': 'key', 'location': 'southeastasia', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7d90992b9a50>, 'traffic': {}, 'mirror_traffic': {}, 'kind': 'Managed'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1748375218035
        },
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Model, ManagedOnlineDeployment, CodeConfiguration\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "# Create deployment for the multi-model setup\n",
        "model_deployment = ManagedOnlineDeployment(\n",
        "    name=\"stacked-pdm-deployment\",\n",
        "    endpoint_name=\"pdm-stacked-model\",\n",
        "    model=\"predictive_maintenance_custom_model:16\",\n",
        "    environment=\"sklearn-env:4\",\n",
        "    code_configuration=CodeConfiguration(\n",
        "           code=\"./src\", scoring_script=\"score.py\"\n",
        "       ),\n",
        "    instance_type=\"STANDARD_F4S_v2\",\n",
        "    instance_count=1,\n",
        "    app_insights_enabled=True\n",
        ")\n",
        "\n",
        "# Deploy the multi-model deployment\n",
        "ml_client.online_deployments.begin_create_or_update(model_deployment)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Check: endpoint pdm-stacked-model exists\n\u001b[32mUploading src (0.04 MBs): 100%|██████████| 36467/36467 [00:00<00:00, 1477927.61it/s]\n\u001b[39m\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 50,
          "data": {
            "text/plain": "<azure.core.polling._poller.LROPoller at 0x7d9085577910>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "..........................................."
        }
      ],
      "execution_count": 50,
      "metadata": {
        "gather": {
          "logged": 1748376678636
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint.traffic = {\"stacked-pdm-deployment\": 100}\n",
        "ml_client.begin_create_or_update(endpoint).result()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 43,
          "data": {
            "text/plain": "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://pdm-stacked-model.southeastasia.inference.ml.azure.com/score', 'openapi_uri': 'https://pdm-stacked-model.southeastasia.inference.ml.azure.com/swagger.json', 'name': 'pdm-stacked-model', 'description': 'Online endpoint for Stacked Predictive Maintenance model', 'tags': {}, 'properties': {'createdBy': 'JEMIMA SIMONE MANUEL', 'createdAt': '2025-05-27T19:45:56.179950+0000', 'lastModifiedAt': '2025-05-27T20:01:11.240860+0000', 'azureml.onlineendpointid': '/subscriptions/55fc198d-597c-451e-9372-e172883e1ef0/resourcegroups/case-study-rg/providers/microsoft.machinelearningservices/workspaces/ml-intern-ws/onlineendpoints/pdm-stacked-model', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/55fc198d-597c-451e-9372-e172883e1ef0/providers/Microsoft.MachineLearningServices/locations/southeastasia/mfeOperationsStatus/oeidp:94050ec3-7333-45e5-8cc0-7313ec07b6be:c07060a2-e2c7-4505-8516-2355a24a1fd9?api-version=2022-02-01-preview'}, 'print_as_yaml': False, 'id': '/subscriptions/55fc198d-597c-451e-9372-e172883e1ef0/resourceGroups/case-study-rg/providers/Microsoft.MachineLearningServices/workspaces/ml-intern-ws/onlineEndpoints/pdm-stacked-model', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/jmanuel/code/Users/jemima.simone.manuel/predictive-maintenance', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7d9098b01ba0>, 'auth_mode': 'key', 'location': 'southeastasia', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7d90b88f98a0>, 'traffic': {'stacked-pdm-deployment': 100}, 'mirror_traffic': {}, 'kind': 'Managed'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 43,
      "metadata": {
        "gather": {
          "logged": 1748376102179
        },
        "jupyter": {
          "outputs_hidden": true
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DEMO"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit requests"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1748377660504
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {script_folder}/app.py\n",
        "import streamlit as st\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "\n",
        "SCORING_URI = \"https://pdm-stacked-model.southeastasia.inference.ml.azure.com/score\"\n",
        "API_KEY = \"6fqbOYAIllFUZTJkPHBWJ0SbeS4JwwSWTcqygx40NctMVXOk9N95JQQJ99BEAAAAAAAAAAAAINFRAZML20cs\"\n",
        "\n",
        "st.set_page_config(page_title=\"Predictive Maintenance Demo\", layout=\"centered\")\n",
        "\n",
        "st.title(\"⚙️ Predictive Maintenance Model Demo\")\n",
        "st.markdown(\"Enter machine sensor readings to predict potential equipment failure.\")\n",
        "\n",
        "st.sidebar.header(\"Input Parameters\")\n",
        "\n",
        "# Input fields using Streamlit widgets\n",
        "# You can use st.sidebar for inputs to make the main area cleaner\n",
        "machine_type = st.sidebar.selectbox(\"Machine type\", [\"L\", \"M\", \"H\"])\n",
        "air_temp = st.sidebar.number_input(\"Air temperature (°C)\", value=298.5, format=\"%.1f\")\n",
        "process_temp = st.sidebar.number_input(\"Process temperature (°C)\", value=310.2, format=\"%.1f\")\n",
        "rotational_speed = st.sidebar.number_input(\"Rotational speed (rpm)\", value=2861.0, format=\"%.1f\")\n",
        "torque = st.sidebar.number_input(\"Torque (Nm)\", value=4.0, format=\"%.1f\")\n",
        "tool_wear = st.sidebar.number_input(\"Tool wear (min)\", value=143.0, format=\"%.1f\")\n",
        "\n",
        "st.write(\"---\") # Separator for visual appeal\n",
        "\n",
        "if st.button(\"🚀 Predict Failure\"):\n",
        "    # Prepare the input data in the format your model expects\n",
        "    input_data = {\n",
        "        \"Machine type\": machine_type,\n",
        "        \"Air temperature\": air_temp,\n",
        "        \"Process temperature\": process_temp,\n",
        "        \"Rotational speed\": rotational_speed,\n",
        "        \"Torque\": torque,\n",
        "        \"Tool wear\": tool_wear\n",
        "    }\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\"\n",
        "    }\n",
        "\n",
        "    st.subheader(\"Prediction Result:\")\n",
        "    try:\n",
        "        # Make the POST request to your Azure ML endpoint\n",
        "        response = requests.post(SCORING_URI, data=json.dumps(input_data), headers=headers)\n",
        "        response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)\n",
        "\n",
        "        prediction_result = response.json()\n",
        "\n",
        "        if prediction_result.get(\"failure\") == \"yes\":\n",
        "            st.error(f\"⚠️ **FAILURE PREDICTED!**\")\n",
        "            st.write(f\"**Potential Failure Type:** **`{prediction_result.get('failure_type', 'Unknown')}`**\")\n",
        "            st.warning(\"Immediate attention or scheduled maintenance is recommended.\")\n",
        "        else:\n",
        "            st.success(\"✅ **No Failure Predicted.**\")\n",
        "            st.write(\"Machine appears to be operating within normal parameters.\")\n",
        "            st.info(\"Continue regular monitoring.\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        st.error(f\"An error occurred while calling the model endpoint: {e}\")\n",
        "        if hasattr(response, 'status_code'):\n",
        "            st.error(f\"Status Code: {response.status_code}\")\n",
        "            st.error(f\"Response Text: {response.text}\")\n",
        "    except json.JSONDecodeError:\n",
        "        st.error(\"Failed to decode JSON response from the model.\")\n",
        "        st.error(f\"Raw response: {response.text}\")\n",
        "\n",
        "st.write(\"---\")\n",
        "st.caption(f\"Powered by Azure ML Endpoint: {SCORING_URI}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing src/app.py\n"
        }
      ],
      "execution_count": 52,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "streamlit run app.py"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (3737097518.py, line 1)",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[53], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    streamlit run app.py\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "execution_count": 53,
      "metadata": {
        "gather": {
          "logged": 1748377882295
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}